[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Course syllabus",
    "section": "",
    "text": "Course information\nInstructor: Trevor Ruiz (he/him/his) [email]\nClass meetings:\n\n[Section 01/3585] 4:10pm – 5:00pm MTWR Construction Innovations Center Room C201\n[Section 02/3430] 5:10pm – 6:00pm MTWR Construction Innovations Center Room C201\n\nOffice hours: 1:00pm – 3:00pm TR 25-236 and by appointment\nProbability is the mathematics of random events. It is an active field of study and provides the theoretical foundation for the discipline of statistics. This course aims to formalize familiar probability concepts covered in prior coursework (predominantly STAT 305), including probability rules, random variables, common distributions, and expected value. We will build on prior experience and intuition and develop tools to support deeper inquiry and subsequent study of mathematical statistics in STAT 426 and STAT 427. Students will also be introduced to potentially new concepts that play central roles in statistics such as joint distributions, transformations, and conditional expectation. Lectures will provide an exposition of definitions, properties, theorems, and examples, and offer a venue for discussion; students will practice applying this material to solve probability problems on homework assignments and demonstrate fluency with key concepts on in-class exams.\n\n\nCatalog Description\nRigorous development of probability theory. Probability axioms, combinatorial methods, conditional and marginal probability, independence, random variables, univariate and multivariate probability distributions, conditional distributions, transformations, order statistics, expectation and variance. Use of statistical simulation throughout the course. 4 lectures. Prerequisite: MATH 241; MATH 248 or CSC 348; and STAT 305. Recommended: STAT 301.\n\n\nTextbook and references\nThere is no required textbook for the course. However, the overall course organization will closely follow chapters 1 through 4 of DeGroot & Schervish, and exposition of this material will follow Hogg & Craig, which is slightly more formal in style. These books are listed below.\n\n(recommended) DeGroot & Schervish, Probability and Statistics, 4th edition, Addison-Wesley.\n(reference) Hogg, McKean, & Craig, Introduction to Mathematical Statistics, 8th edition, Pearson.\n\nDesk copies of DeGroot & Schervish are available in StatLab (25-107B).\n\n\nLearning outcomes\nThe course aims to enable students to:\n\nuse the axiomatic construction of probability to derive properties of probability measures and conditional probability measures, and apply definitions and properties to solve probability problems \nconstruct probability models for discrete and continuous random variables, develop familiarity with common probability distributions, and use distribution functions to derive properties such as expectations and variances \ndetermine joint distributions for collections of random variables, and use joint distribution functions to (a) derive properties such as covariance and correlation, (b) to determine conditional and marginal distributions, and (c) derive distributions of transformations and functions of one or more random variables \n\n\n\nAssessments\nAttainment of learning outcomes will be measured by evaluation of submitted homework assignments and exams. Letter grades will be assigned based on a weighted average of scores, with the relative weighting approximately as indicated in parentheses below.\n\nHomeworks (50%). Homework assignments will be given approximately weekly (except for exam weeks and holidays). The goal of homework assignments is to provide opportunities for students to reinforce key concepts, definitions, and results through practice and to develop and apply problem-solving abilities. These will be distributed on Thursday each week in which they are assigned and due in class the following Thursday; in general, each assignment will consist of questions pertaining to material discussed in class during the preceding week. Students are encouraged to collaborate on homework assignments, but are expected to prepare submissions individually and indicate in writing on their submission any classmates they collaborated with (see collaboration policy below). Submissions should reflect students’ best effort and will be evaluated based on completeness, organization, and correctness of selected answers. Each student’s lowest homework score will be omitted in grade calculations; otherwise, all homework scores will be weighted equally.\nMidterms (30%). Two midterm exams will be given during the quarter at approximately four-week intervals as shown on the tentative schedule below. The goal of the midterm exams is to assess students’ ability to use key concepts, definitions, and results in furtherance of course learning outcomes. Midterms will be given in class on Thursdays during indicated weeks and consist of 2-3 questions that must be answered individually during the allotted time without consulting anyone except the instructor. Students will be allowed one sheet of notes that they may consult while taking each exam. Answers will be evaluated based on completeness and correctness. While both midterm exams will count towards final grades, whichever exam receives the higher score will be weighted more heavily in grade calculations.\nFinal (20%). A final exam will be given in the usual classroom at the time scheduled by the registrar. The goal of the final exam is to assess students’ integration of the course material in furtherance of course learning oucomes. For Section 01, the final will be held on Wednesday, December 13, 4:10pm — 7:00pm; for Section 02, the final will be held on Friday, December 15, 4:10pm — 7:00pm. The final will consist of 4-6 questions that must be answered individually during the allotted time without consulting anyone except the instructor. Students will be allowed one sheet of notes that they may consult while taking the final. Its scope will be cumulative but emphasis will be on later material. Answers will be evaluated based on completeness and correctness.\n\nEvery effort will be made to return evaluated work within one week of submission. Final exams, per University policy, will be retained by the instructor. Scores will be recorded in Canvas, and students will be responsible for checking their scores to ensure accurate data entry upon receipt of evaluated work.\nVery roughly, letter grades will be assigned as follows. A: 90-100. B: 75-90. C: 60-75. D: 50-60. However, please note that letter grades represent qualitative assessments of attainment of course objectives, and as such these ranges may be adjusted at instructor discretion to ensure apporpriate correspondence with letter grade definitions based on course assessments. Please also note that failure to adhere to course policies — particularly collaboration, academic integrity, and attendance policies — may result in a lower letter grade than would otherwise be assigned.\n\n\nTentative schedule\nSubject to change at instructor discretion.\n\n\n\n\n\n\n\n\n\nWeek\nLecture Topic\nSuggested reading\nAssignments\n\n\n\n\n0 (9/21)\nCourse introduction\n\n\n\n\n1 (9/25)\nProbability axioms and properties\n1.4–1.6\nHW1\n\n\n2 (10/2)\nCounting methods\n1.7–1.10\nHW2\n\n\n3 (10/9)\nConditional probability and independence\n2.1–2.2\nHW3\n\n\n4 (10/16)\nBayes’ theorem\n2.3–2.4\nMidterm 1\n\n\n5 (10/23)\nDiscrete and continuous random variables\n3.1–3.3\nHW4\n\n\n6 (10/30)\nJoint and conditional distributions\n3.4–3.7\nHW5\n\n\n7 (11/6)\nTransformations and order statistics\n3.8–3.9\nHW6\n\n\n8 (11/13)\nExpectation\n4.1–4.2\nMidterm 2\n\n\nFall break (11/20)\n\n\n\n\n\n9 (11/27)\nVariance and covariance\n4.3, 4.6\nHW7\n\n\n10 (12/4)\nConditional expectation\n4.7\n\n\n\nFinals (12/11)\n\n\nFinal\n\n\n\n\n\nCourse policies\n\nCollaboration\nCollaboration within the class (including across class sections) is allowed (and encouraged!) on homework assignments, subject to certain conditions outlined in the paragraph below. Collaboration does not include consulting individuals outside of the class. Students collaborating with a group are expected to prepare their own solutions, in their own words and writing, and are required to indicate their collaborators in writing on their submission. Submissions that do not indicate any collaborators will be understood to represent the sole and independent effort of the student named on the submission.\nA collaboration is a shared effort. Students that choose to work together on homework assignments are expected to make material contributions towards producing one or more shared answers or solutions. Material contributions might include participation in discussions, critique of a proposed solution, or presentation of a problem approach. In the absence of such contributions, submitting shared answers is not appropriate and, depending on the circumstances, may constitute an act of dishonesty. The best way to ensure that a group effort is consistent with this collaboration policy is to agree that all team members will attempt all or most of each assignment individually prior to engaging in any discussions.\n\n\nAttendance\nRegular attendance is essential for success in the course and required per University policy. Each student may miss two class meetings without notice but subsequent absences should be excusable and students should notify the instructor. Unexcused absences may negatively impact course grades.\n\n\nCommunication and email\nStudents are encouraged to use face-to-face means of communication (office hours, class meetings, appointments) when possible. Email may be used on a secondary basis or when a written record of communication is needed. Every effort is made to respond to email within 48 weekday hours — so a message sent Thursday or Friday may not receive a reply until Monday or Tuesday. Time-sensitive messages should be identified as such in the subject line. Students should wait one week before sending a reminder.\n\n\nTime commitment\nSTAT425 is a four-credit course, which corresponds to a minimum time commitment of 12 hours per week, including lectures, reading, homework assignments, and study time. Some variability in workload by week should be expected, and most students will need to budget a few extra hours each week. However, students can expect to be able to meet course expectations with a time commitment less than 16 hours per week, and are encouraged to notify the instructor if they are regularly exceeding this amount.\n\n\nAssignment scores and final grades\nEvery effort will be made to provide consistent and fair evaluation of student work. Students should notify the instructor of any errors and/or discrepancies in evaluation promptly and on an assignment-by-assignment basis (i.e., not at the end of the quarter) to guarantee consideration for correction. Final grades will only be changed in the case of clerical errors. Attempting to negotiate scores or final grades is not appropriate. Per University policy, faculty have final responsibility for grading criteria and grading judgment and have the right to alter student assessment or other parts of the syllabus during the term. If any student feels their grade is unfairly assigned at the end of the course, they have the right to appeal it according to the procedure outlined here.\n\n\nLate work\nEach student may turn in two homework assignments up to one week late without penalty at any time during the quarter and without notice. Subsequently, assignments turned in up to one week late will be evaluated for 75% credit unless an extension is granted in advance. No late work will be accepted beyond one week after the original due date. This policy applies to homework assignments only, and not exams.\n\n\nAccommodations\nIt is University policy to provide, on a flexible and individualized basis, reasonable accommodations to students who have disabilities that may affect their ability to participate in course activities or to meet course requirements. Accommodation requests should be made through the Disability Resource Center (DRC).\n\n\nConduct and Academic Integrity\nStudents are expected to be aware of and adhere to University policy regarding academic integrity and conduct. Detailed information on these policies, and potential repercussions of policy violations, can be found via the Office of Student Rights & Responsibilities (OSRR).\n\n\nCopyright and distribution of course materials\nAll course materials, including handouts, homework assignments, study guides, course notes, exams, and solutions are subject to copyright; students are not permitted to share or distribute any course materials without the explicit written consent of the instructor. This includes, in particular, uploading materials or prepared solutions to online services and sharing materials or prepared solutions with students who may take the course in a future term. Transgressions of this policy compromise the effectiveness of course assessments and do a disservice to future students."
  },
  {
    "objectID": "content/week3-conditional.html",
    "href": "content/week3-conditional.html",
    "title": "Conditional probability",
    "section": "",
    "text": "Let \\((S, \\mathcal{S}, P)\\) be a probability space and let \\(A \\in \\mathcal{S}\\) be an event with \\(P(A) &gt; 0\\). The conditional probability of any event \\(E\\in\\mathcal{S}\\) given \\(A\\) is defined as: \\[\nP(E\\;|A) = \\frac{P(E\\cap A)}{P(A)}\n\\]\nThis is interpreted as the chance of \\(E\\) provided that \\(A\\) has occurred. Importantly, \\(E|A\\) is not an event; rather, \\(P(\\cdot\\;| A)\\) is a new probability measure. To see this, check the axioms:\n\n(A1) Since \\(P\\) is a probability measure, \\(P(E\\cap A) \\geq 0\\), so it follows \\(P(E\\;|A) = \\frac{P(E\\cap A)}{P(A)} \\geq 0\\).\n(A2) \\(P(S\\;|A) = \\frac{P(S\\cap A)}{P(A)} = \\frac{P(A)}{P(A)} = 1\\)\n(A3) If \\(\\{E_i\\}\\) is a disjoint collection, then \\(\\{E_i \\cap A\\}\\) is also a disjoint collection, so by countable additivity of \\(P\\), one has: \\[\nP\\left(\\bigcup_i E_i \\;\\big|\\; A\\right) = \\frac{P\\left(\\left[\\bigcup_i E_i\\right]\\cap A\\right)}{P(A)} = \\frac{P\\left(\\bigcup_i (E_i\\cap A)\\right)}{P(A)} = \\sum_i \\frac{P(E_i\\cap A)}{P(A)} = \\sum_i P(E_i\\;|A)\n\\]\n\nOne can view \\(P(\\cdot\\;|A)\\) as a probability measure on \\((S, \\mathcal{S})\\), or as a probability measure on \\(\\left(A, \\mathcal{S}^A\\right)\\) where \\(\\mathcal{S}^A = \\{E\\cap A: E \\in \\mathcal{S}\\}\\). Some prefer the latter view, since it aligns with the interpretation that by conditioning on \\(A\\) one is redefining the sample space.\n\nBasic properties\nAn immediate consequence of the definition is that: \\[\nP(E\\cap A) = P(E\\;| A) P(A)\n\\]\nIn fact, this multiplication rule for conditional probabilities can be generalized to an arbitrary finite collection of events: \\[\nP\\left(\\bigcap_{i = 1}^n E_i\\right) = P(E_1) \\times P(E_2\\;|E_1) \\times P(E_3\\;|E_1 \\cap E_2) \\times\\cdots\\times P(E_n\\;| E_1 \\cap \\cdots \\cap E_{n - 1})\n\\]\nOr, written more compactly: \\[\nP\\left(\\bigcap_{i = 1}^n E_i\\right) = P(E_1) \\times \\prod_{i = 2}^n P\\left(E_i \\;\\Bigg| \\bigcap_{j = 1}^{i - 1} E_j \\right)\n\\]\n\n\n\n\n\n\nProof\n\n\n\nApply the definition of conditional probability to the terms in the product on the right hand side to see that: \\[\n\\begin{align*}\nP(E_1) \\times \\prod_{i = 2}^n P\\left(E_i \\;\\Bigg| \\bigcap_{j = 1}^{i - 1} E_j \\right)\n&= P(E_1) \\times \\prod_{j = 2}^n \\left[\\frac{P\\left(\\bigcap_{j = 1}^i E_j\\right)}{P\\left(\\bigcap_{j = 1}^{i - 1} E_j \\right)}\\right] \\\\\n&= P(E_1) \\times \\frac{P\\left(\\bigcap_{j = 1}^2 E_j\\right)}{P\\left( E_1 \\right)}\n  \\times \\frac{P\\left(\\bigcap_{j = 1}^3 E_j\\right)}{P\\left(\\bigcap_{j = 1}^{2} E_j \\right)}\n  \\times\\cdots\n  \\times \\frac{P\\left(\\bigcap_{j = 1}^n E_j\\right)}{P\\left(\\bigcap_{j = 1}^{n - 1} E_j \\right)}\n\\end{align*}\n\\] Then notice that all terms cancel, leaving only \\(P\\left(\\bigcap_{j = 1}^n E_j\\right)\\), and establishing the result.\n\n\nThe multiplication rule provides a convenient way to compute certain probabilities, as in some problems it’s easier to find a conditional probability than an unconditional one.\n\n\n\n\n\n\nExample: (more) poker hands\n\n\n\nConsider drawing 5 cards at random. What’s the probability that all 5 are diamonds?\nThis could be found by computing the total number of ways to draw 5 diamonds out of the total number of ways to draw 5 cards: \\[\n\\frac{{13 \\choose 5}}{{52 \\choose 5}}\n= \\frac{13!}{5!8!}\\times\\frac{5!47!}{52!}\n\\] Or, one can avoid evaluating the factorials and instead notice that the conditional probability of drawing a diamond given having already drawn \\(k\\) diamonds is \\(\\frac{13 - k}{52 - k}\\) — the number of diamonds left as a proportion of the number of cards left — so: \\[\nP\\left(\\text{5 diamonds}\\right) = \\frac{13}{52}\\times\\frac{12}{51}\\times\\frac{11}{50}\\times\\frac{10}{49}\\times\\frac{9}{48} \\approx 0.000495\n\\]\nFor a quick exercise, check the result by simplifying the factorials in the first solution.\nTo see why this is an application of the multiplication rule for conditional probabilities more formally, let \\(E_i = \\{\\text{draw a diamond on the $k$th draw}\\}\\). Then: \\[\n\\begin{align*}\nP\\left(\\text{5 diamonds}\\right)\n&= P(E_1 \\cap E_2 \\cap E_3 \\cap E_4 \\cap E_5) \\\\\n&= P(E_1)\n  \\times P(E_2\\;| E_1)\n  \\times P(E_3\\;| E_1 \\cap E_2) \\\\\n  &\\qquad\\times P(E_4 \\;| E_1 \\cap E_2 \\cap E_3)\n  \\times P(E_5\\;| E_1 \\cap E_2 \\cap E_3 \\cap E_4)\n\\end{align*}\n\\]\n\n\nAnother useful property is the law of total probability: if \\(\\{A_i\\}\\) is a partition of the sample space \\(S\\), then for any event \\(E \\in \\mathcal{S}\\) one has: \\[\nP(E) = \\sum_i P(E\\;| A_i) P(A_i)\n\\]\n\n\n\n\n\n\nProof\n\n\n\nNote that \\(E = E \\cap S = E\\cap \\left[\\bigcup_i A_i\\right] = \\bigcup_i (E \\cap A_i)\\). Since \\(\\{A_i\\}\\) is disjoint, so is \\(\\{E \\cap A_i\\}\\). Then by countable additivity: \\[\nP(E) = P\\left[\\bigcup_i (E \\cap A_i)\\right] = \\sum_i P(E \\cap A_i)\n\\] And by the multiplication rule for conditional probabilities \\(P(E\\cap A_i) = P(E\\;| A_i) P(A_i)\\) so: \\[\nP(E) = \\sum_i P(E \\cap A_i) = \\sum_i P(E\\;| A_i) P(A_i)\n\\]\n\n\n\n\n\n\n\n\nExample: CVD rates\n\n\n\nIt’s estimated that 8% of men and 0.5% of women have color vision deficiency (CVD). Supposing that exactly these proportions appear in a group of 400 women and 200 men, what’s the probability that a randomly selected individual has CVD?\nFrom the problem set-up:\n\n\\(P(\\text{CVD}\\;| M) = 0.08\\) and \\(P(\\text{CVD}\\;| F) = 0.005\\)\n\\(P(M) = \\frac{1}{3}\\) and \\(P(F) = \\frac{2}{3}\\)\n\nNote that these are the probabilities of selecting a person with the specified attributes from this group, assuming all individuals are equally likely to be selected. This is consistent with how we’ve defined probabilities for finite sample spaces. The meaning of the probability here comes from sampling from this group of people at random; these are not statements about the chance of having CVD, or being of one sex or the other, or the like.\nThe law of total probability yields: \\[\n\\begin{align*}\nP(\\text{CVD})\n&= P(\\text{CVD}\\;| M) P(M) + P(\\text{CVD}\\;| F) P(F) \\\\\n&= 0.08 \\cdot \\frac{1}{3} + 0.005 \\cdot\\frac{2}{3} \\\\\n&= 0.03\n\\end{align*}\n\\]\n\n\n\n\nIndependence\nIf two events are independent, then the occurrence of one event doesn’t affect the probability of the other. For example, obtaining heads in a coin toss doesn’t affect the chances of obtaining a heads in a subsequent toss.\nFor independent events, conditioning on one event does not change the probability of the other: if \\(E\\) and \\(A\\) are independent then \\(P(E\\;|A) = P(E)\\). Equivalently: \\[\nP(A \\cap B) = P(A)P(B)\n\\]\n\n\nBayes’ theorem"
  },
  {
    "objectID": "content/hw2.html",
    "href": "content/hw2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Please prepare your solutions neatly, numbered, and in order; ideally, you’ll write up a final clean copy after completing all problems on scratch paper. Please note that if a prompt includes a question, you’re expected to support answers with reasoning, even if the prompt does not explicitly ask for a justification. Provide your name at the top of your submission, and if you collaborate with other students in the class, please list their names at the top of your submission beneath your own.\n\n(Hypergeometric distribution) Imagine a clown car with 50 clowns; suppose that 20 of them are happy clowns and 30 of them are sad clowns.\n\nIf 10 clowns exit the car sequentially and at random, what is the probability that exactly 3 are sad clowns?\nIf 10 clowns exit the car sequentially and at random, what is the probability that exactly \\(k\\) are sad clowns? (Assume \\(0\\leq k \\leq 10\\).)\nIf \\(n\\) clowns exit the car sequentially and at random, what is the probability that exactly \\(k\\) are sad clowns? (Assume \\(0 \\leq k \\leq n\\) and \\(n &lt; 50\\).)\nIf the car contains \\(N\\) happy clowns and \\(M\\) sad clowns and \\(n \\leq N + M\\) exit the car sequentially and at random, what is the probability that \\(k\\) are happy clowns (for \\(0 \\leq k \\leq n\\))?\n\nConsider rolling two six-sided dice. The sample space is \\(S = \\{1, 2, 3, 4, 5, 6\\}^2\\). Assuming the dice are fair, each outcome \\((i, j)\\) has equal probability \\(p\\). Consider the event that the dice sum to \\(k\\): \\(E_k = \\{(i, j)\\in S: i + j = k\\}\\).\n\nFind \\(|S|\\) and \\(p\\).\nFind \\(|E_k|\\) in terms of \\(k\\).\nMake a table of the probabilities \\(P(E_k)\\).\nInterpret the event \\(\\bigcup_{k = 1}^m E_k\\) in words and find \\(P\\left(\\bigcup_{k = 1}^m E_k\\right)\\) (assuming \\(1\\leq m \\leq 12\\)).\nFind the probability of rolling a sum smaller than or equal to 8.\n\n\nHint: you may find the proof of SWR2 helpful in answering part (ii); however, there are multiple ways to solve the problem.\n\nVerify the following identities.\n\n\\({n \\choose k} = (k + 1){n \\choose k + 1}\\)\n\\({n + m \\choose m} = {n + m \\choose n}\\)\n\\({n \\choose 1} = {n \\choose n - 1} = n\\)\n\\({n \\choose k} = {n \\choose n - k}\\)\n\\({n \\choose k} = \\frac{n}{k}{n - 1 \\choose k - 1}\\)\n\nConsider a lottery where players can choose 12 numbers between 0 and 50 (including 0 and 50) and one winning combination is drawn by randomly selecting one number at a time. Suppose there are three prizes: the biggest prize is awarded to a match of all numbers in the winning combination in sequence; the second biggest prize is awarded to a match of all numbers in the winning combination, but not in sequence; and a smaller cash prize is awarded for matching all but one number in the winning combination, and not necessarily in sequence.\n\nWhat is the probability of winning each prize if player selections (and the winning combination) can include each number no more than once?\nWhat is the probability of winning each prize if player selections (and the winning combination) can include any number multiple times?\nWhat is the probability of winning any of the prizes under each of the scenarios in (i) and (ii)?\n\nSuppose that you have \\(n\\) letters addressed to distinct recipients and \\(n\\) envelopes addressed accordingly, and the letters are placed in the envelopes at random and mailed. Let \\(A_i = i\\text{th letter is placed in the correct envelope}\\).\n\nFind the probability that the \\(i\\)th letter is placed in the correct envelope: determine \\(P(A_i)\\).\nFind the probability that the \\(i\\)th and \\(j\\)th letters are placed in the correct envelopes: determine \\(P(A_i \\cap A_j)\\) assuming \\(1 \\leq i &lt; j \\leq n\\).\nFind \\(\\sum_{1 \\leq i &lt; j \\leq n} P(A_i \\cap A_j)\\). (Hint: how many ways are there to choose two letters?)\nFind the probability that the \\(i\\)th, \\(j\\)th, and \\(k\\)th letters are placed in the correct envelopes: determine \\(P(A_i \\cap A_j \\cap A_k)\\) assuming \\(1 \\leq i &lt; j &lt; k \\leq n\\).\nFind \\(\\sum_{1 \\leq i &lt; j &lt; k \\leq n} P(A_i \\cap A_j \\cap A_k)\\). (Hint: how many ways are there to choose three letters?)\nFind the probability that an arbitrary subcollection of \\(i\\) letters (say, letters \\(j_1, \\dots, j_i\\)) are all placed in the right envelopes: determine \\(P(A_{j_1}\\cap A_{j2} \\cap \\cdots \\cap A_{ji})\\) assuming \\(1 \\leq j_1 &lt; \\cdots &lt; j_i \\leq n\\).\nFind \\(\\sum_{1 \\leq j_1 &lt; \\cdots &lt; j_i \\leq 1} P(A_{j_1} \\cap \\cdots \\cap A_{j_i})\\).\nUse the inclusion-exclusion formula to find the probability that at least one letter is mailed to the correct recipient. What is the limit of this probability as \\(n \\rightarrow \\infty\\)?"
  },
  {
    "objectID": "content/hw1.html",
    "href": "content/hw1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Please prepare your solutions neatly, numbered, and in order; ideally, you’ll write up a final clean copy after completing all problems on scratch paper. Please note that if a prompt includes a question, you’re expected to support answers with reasoning, even if the prompt does not explicitly ask for a justification. Provide your name at the top of your submission, and if you collaborate with other students in the class, please list their names at the top of your submission beneath your own.\n\n(Serial systems) In a serial system, components are linked together in such a way that the system only works if every component works. For example, consider a string of Christmas lights; if one light goes out, the whole string goes out. Suppose that one has a serial system with \\(k\\) components that all function independently of one another. The state of the system can be represented by a binary vector \\(x = (x_1, \\dots, x_k)\\) where the coordinate \\(x_i\\) indicates whether the \\(i\\)th component is working. The relevant sample space is the set of all possible values of \\(x\\), that is, \\(S = \\{(x_1, \\dots, x_k): x_i \\in \\{0, 1\\}\\}\\), so that the system states are the outcomes, and the events are all possible subsets \\(\\mathcal{S} = 2^S\\). Let \\(E_i \\in \\mathcal{S}\\) denote the event that the \\(i\\)th component works.\n\nExpress the sample space \\(S\\) as a Cartesian product.\nExpress the event \\(E_i\\) as a set in terms of the system states \\(x \\in S\\).\nList two distinct outcomes included in \\(E_1\\) and two distinct outcomes included in \\(E_2\\).\nIs \\(\\{E_i\\}\\) a disjoint collection? Why or why not?\nFind the number of system states \\(|S|\\) and the number of possible events \\(|\\mathcal{S}|\\).\n\nContinuing the example in the previous problem, express each of the following events in terms of the collection \\(\\{E_i\\}\\).\n\nThe first component works and the second component fails.\nThe first three components work.\nThe system works.\nThe system fails.\nExactly one component fails.\n\nConsider the monotone sequences of sets defined by \\(A_n = [0, 1 + \\frac{1}{n})\\) and \\(B_n = [0, 1 - \\frac{1}{n})\\).\n\nIs \\(\\{A_n\\}\\) increasing or decreasing?\nIs \\(\\{B_n\\}\\) increasing or decreasing?\nTrue or false: \\(\\lim_{n \\rightarrow\\infty} A_n = \\lim_{n\\rightarrow\\infty} B_n\\)? Explain. (Hint: \\(x \\in \\bigcup_n C_n\\) just in case \\(x \\in C_n\\) for at least one \\(n\\); similarly, \\(x \\in \\bigcap_n C_n\\) just in case \\(x \\in C_n\\) for every \\(n\\).)\n\nConsider the “experiment” of rolling 2 six-sided dice, and denote the outcomes by pairs \\((i, j)\\) where \\(i, j \\in \\{1, 2, 3, 4, 5, 6\\}\\).\n\nWrite the sample space \\(S\\) for this experiment, assuming the order of the dice does not matter (i.e., \\((3, 2) = (2, 3)\\)), and find \\(|S|\\).\nIf \\(P(E) = 1\\) whenever \\(E = \\{(1, 1)\\}\\) and \\(P(E) = 0\\) otherwise for \\(E \\in 2^S\\), is \\(P\\) a valid probability measure? Why or why not?\nIf \\(P(E) = 1\\) whenever \\((1, 1) \\in E\\) and \\(P(E) = 0\\) otherwise for \\(E \\in 2^S\\), is \\(P\\) a valid probability measure? Why or why not?\n\n(Uniform distribution) [OPTIONAL] Consider the triple \\((S, \\mathcal{S}, P)\\) where:\n\\[\n\\begin{align*}\nS &= [0, 1] \\\\\n\\mathcal{S} &= \\left\\{A \\subseteq S: A \\text{ is a countable union or intersection of open or closed intervals or their complements}\\right\\} \\\\\nP(E) &= \\int_E dx,\\quad E\\in\\mathcal{S} \\qquad\\text{(i.e., total length of $E$)}\n\\end{align*}\n\\]\n\nShow that \\((S, \\mathcal{S}, P)\\) is a probability space by verifying the requisite conditions on \\(\\mathcal{S}\\) and \\(P\\).\nLet \\(\\mathcal{C}\\) denote the Cantor set. Show that \\(P(\\mathcal{C}) = 0\\).\n\nRemark: the integral \\(\\int_E dx\\) is defined as follows:\n\nfor contiguous intervals, \\(\\int_{(a, b)} dx = \\int_{[a, b]} dx = \\int_{[a, b)} dx = \\int_{(a, b]} dx = \\int_a^b dx\\)\nfor disjoint intervals \\(E_i\\), \\(\\int_{\\bigcup_i E_i} dx = \\sum_i \\int_{E_i} dx\\)\n\nLet \\((S, \\mathcal{S}, P)\\) be a probability space, and let \\(\\{E_i\\}\\) be a collection of events. Show that if \\(\\{E_i\\}\\) is a finite or countable partition of any event \\(A \\subseteq S\\), then \\(\\sum_i P(E_i) = P(A)\\).\n(Bonferroni inequality) Use results from class to show that \\(P\\left(\\bigcap_{i = 1}^n E_i\\right) \\geq 1 - \\sum_{i = 1}^n P\\left(E^C\\right)\\)."
  },
  {
    "objectID": "content/week1-sets.html",
    "href": "content/week1-sets.html",
    "title": "Sets",
    "section": "",
    "text": "Concepts\nA set is a collection of mathematical objects such as numbers, points, functions, or more sets.\nIf an object \\(x\\) is in a set \\(A\\), we say that \\(x\\) is an element of \\(A\\) and write \\(x \\in A\\) to mean “\\(x\\) is in \\(A\\)”. Otherwise, we write \\(x \\not\\in A\\).\nWe write a set by identifying its elements. For example:\n\\[\nA =\\{1, 2, 3, 4, 5\\}\n\\]\nTwo sets \\(A, B\\) are identical just in case they have exactly the same elements:\n\\[\nA = B\n\\quad\\Longleftrightarrow\\quad\nx \\in A \\Leftrightarrow x \\in B\n\\]\n\n\nSpecial sets\nThere are some special notations for the sets of numbers:\n\n\\(\\mathbb{R}\\): real numbers\n\\(\\mathbb{N}\\): natural numbers\n\\(\\mathbb{Z}\\): integers\n\\(\\mathbb{C}\\): complex numbers\n\\(\\mathbb{Q}\\): rational numbers\n\nSimilarly, open, closed, and half-open real intervals are denoted:\n\\[\n\\begin{align*}\n[a, b] = \\{x \\in \\mathbb{R}: a \\leq x \\leq b\\} \\\\\n(a, b] = \\{x \\in \\mathbb{R}: a &lt; x \\leq b\\} \\\\\n[a, b) = \\{x \\in \\mathbb{R}: a \\leq x &lt; b\\} \\\\\n(a, b) = \\{x \\in \\mathbb{R}: a &lt; x &lt; b\\}\n\\end{align*}\n\\]\n\n\nContainment\nIf all the elements of a set \\(A\\) are also in \\(B\\), then we say that \\(A\\) is contained in \\(B\\), or that \\(A\\) is a subset of \\(B\\), and write \\(A \\subseteq B\\). (Containment is a binary relation and defines a partial ordering on the set of all sets.)\n\\[\nA \\subseteq B\n\\quad\\Longleftrightarrow\\quad\nx \\in A \\Rightarrow x \\in B\n\\]\nFurther, \\(A\\) is a proper subset of \\(B\\) just in case there is at least one element of \\(B\\) that is not in \\(A\\):\n\\[\nA \\subset B\n\\quad\\Longleftrightarrow\\quad\nA \\subseteq B \\text{ and } A \\neq B\n\\]\nBoth relations are transitive:\n\nIf \\(A \\subseteq B\\) and \\(B \\subseteq C\\) then \\(A \\subseteq C\\)\nIf \\(A \\subset B\\) and \\(B \\subset C\\) then \\(A \\subset C\\)\n\n\n\n\n\n\n\nCheck your understanding\n\n\n\n\nLet \\(A = [0, 1)\\) and \\(B = (0, 1]\\) and \\(C = (0, 2)\\)\n\nTrue or false, \\(A \\subset C\\)\nTrue or false, \\(B \\subset C\\)\n\nList all proper subset relations among \\(\\mathbb{R}, \\mathbb{Q}, \\mathbb{N}, \\mathbb{Z}, \\mathbb{C}\\).\n\n\n\n\n\nNull set\nLastly it may happen that a set contains no elements. This set is called the null set (or empty set) and is denoted \\(\\emptyset = \\{ \\}\\).\nFor a small brain teaser, prove that every set contains the null set: for any set \\(A\\), \\(\\emptyset \\subseteq A\\). Intuitively, this is true; but why, based on the definitions, must it hold? (Hint: the conditional “if \\(p\\) then \\(q\\)” is trivially true if \\(p\\) is always false.)\n\n\nSet operations\nThe two fundamental set operations are union and intersection. Let \\(A, B\\) be sets and define:\n\n(union) \\(A \\cup B = \\{x: x \\in A \\text{ or } x \\in B\\}\\)\n(intersection) \\(A \\cap B = \\{x: x \\in A \\text{ and } x \\in B\\}\\)\n\nBoth operations are associative:\n\\[\n\\begin{align*}\nA \\cup (B \\cup C) = (A \\cup B) \\cup C \\\\\nA \\cap (B \\cap C) = (A \\cap B) \\cap C\n\\end{align*}\n\\]\nAnd distributive:\n\\[\n\\begin{align*}\nA \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C) \\\\\nA \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\n\\end{align*}\n\\]\nProofs are direct and left as an exercise: apply definitions of union/intersection and show that the conditions specified by each construction are equivalent. The properties follow, essentially, from the meanings of “and” and “or”.\nThe operation of set difference corresponds to removing the elements of one set from another set:\n\\[\nA \\setminus B = \\{x: x \\in A \\text{ and } x \\not\\in B\\}\n\\]\nSet difference is not distributive over unions and intersections, but rather exhibits the following properties:\n\\[\n\\begin{align*}\nA \\setminus (B \\cap C) = (A \\setminus B) \\cup (A \\setminus C) \\\\\nA \\setminus (B \\cup C) = (A \\setminus B) \\cap (A \\setminus C)\n\\end{align*}\n\\]\nWe’ll review the proof in class.\nLastly, the Cartesian product between sets is the set of all possible pairs of elements from each set:\n\\[\nA \\times B = \\{(a, b): a \\in A, b \\in B\\}\n\\]\nThe \\(n\\)-fold product of a set \\(A\\) with itself is written \\(A^n\\):\n\\[\nA^n = \\{(a_1, \\dots, a_n): a_i \\in A, i = 1, \\dots, n\\}\n\\]\nThis is a handy construction, for example, in representing:\n\n\\(n\\)-dimensional real space (\\(\\mathbb{R}^n\\))\nan \\(n\\)-dimensional unit cube (\\([0, 1]^n\\))\n32-bit integers (\\(\\{0, 1\\}^{32}\\))\n\n\n\n\n\n\n\nCheck your understanding\n\n\n\n\nLet \\(A = [0, 1)\\) and \\(B = (0, 1]\\) and write the following sets as real intervals.\n\n\\(A \\cup B\\)\n\\(A \\cap B\\)\n\\(B\\setminus A\\)\n\\((A \\cup B) \\setminus (A \\cap B)\\)\n\\((A \\cap B) \\setminus (A \\cup B)\\)\n\n\n\n\n\n\nCardinality\nThe cardinality of a set is the number of elements it contains, and is written \\(|A|\\). We say that:\n\n\\(A\\) is finite if \\(|A| &lt; \\infty\\)\n\\(A\\) is countable if \\(|A| = |\\mathbb{N}|\\)\n\\(A\\) is uncountable if \\(|A| &gt; |\\mathbb{N}|\\)\n\nThe power set of \\(A\\) is the set of all subsets of \\(A\\), and is written:\n\\[\n2^A = \\{B: B \\subseteq A\\}\n\\]\nIf \\(A\\) is finite, \\(|2^A| = 2^{|A|}\\); otherwise, \\(2^A\\) is uncountable. We’ll prove the finite case in class.\n\n\n\n\n\n\nCheck your understanding\n\n\n\n\nIf \\(A = \\{0, 6, 12, 44, 190\\}\\), what is \\(|A|\\)?\nIf \\(A = \\{H, T\\}\\), list all the elements of \\(2^A\\).\nIf \\(A = \\{x \\in \\mathbb{N}: x \\leq 100 \\text{ and } x\\%2 = 0\\}\\), find \\(|A|\\) and \\(|2^A|\\)\n\n\n\n\n\nSequences of sets\nConsider a sequence of sets \\(A_1, A_2, \\dots\\). For short, we write the sequence \\(\\{A_i\\}_{i \\in I}\\) or simply \\(\\{A_i\\}\\), where the index set is implicit from context.\nDefine the union/intersection of the first \\(n\\) sets as follows:\n\\[\n\\begin{align*}\n\\bigcup_{i = 1}^n A_i = A_1 \\cup A_2 \\cup \\cdots \\cup A_n = \\{x: x \\in A_i \\text{ for some } i \\leq n\\} \\\\\n\\bigcap_{i = 1}^n A_i = A_1 \\cap A_2 \\cap \\cdots \\cap A_n = \\{x: x \\in A_i \\text{ for every } i \\leq n\\}\n\\end{align*}\n\\]\nSlightly more generally, one might define the union of a subcollection as \\(\\bigcup_{j \\in J} A_j\\) for some collection of indices in the index set \\(J \\subset \\mathbb{N}\\).\nNow, if the sequence is infinite, the union or intersection of all sets in the sequence is defined as:\n\\[\n\\begin{align*}\n\\bigcup_{n = 1}^\\infty A_n = \\{x: x \\in A_i \\text{ for some } i \\in \\mathbb{N} \\} \\\\\n\\bigcap_{n = 1}^\\infty A_n = \\{x: x \\in A_i \\text{ for every } i \\in \\mathbb{N}\\}\n\\end{align*}\n\\]\nThese are referred to as countable unions and countable intersections.\nWe say that a sequence is monotone if sets are sequentially nested, and more specifically, that the sequence is:\n\nnondecreasing if \\(A_i \\subseteq A_{i + 1}\\) for every \\(i \\in \\mathbb{N}\\)\nincreasing if \\(A_i \\subset A_{i + 1}\\) for every \\(i \\in \\mathbb{N}\\)\nnonincreasing if \\(A_i \\supseteq A_{i + 1}\\) for every \\(i \\in \\mathbb{N}\\)\ndecreasing if \\(A_i \\supset A_{i + 1}\\) for every \\(i \\in \\mathbb{N}\\)\n\nNote that increasing sequences are also nondecreasing, and that decreasing sequences are also nonincreasing. We define the limit of a monotone sequence of sets as the countable union or intersection:\n\\[\n\\begin{align*}\n\\lim_{n\\rightarrow\\infty} A_n = \\bigcap_{n = 1}^\\infty A_n \\quad\\text{(nonincreasing)} \\\\\n\\lim_{n\\rightarrow\\infty} A_n = \\bigcup_{n = 1}^\\infty A_n \\quad\\text{(nondecreasing)}\n\\end{align*}\n\\]\n\n\n\n\n\n\nCheck your understanding\n\n\n\n\nIf \\(\\{A_n\\}\\) is a nondecreasing sequence, what is \\(\\bigcap_{n = 1}^\\infty A_n\\)?\nIf \\(\\{A_n\\}\\) is a nonincreasing sequence, what is \\(\\bigcup_{n = 1}^\\infty A_n\\)?\nIf \\(\\{A_n\\}\\) is a decreasing sequence, what is \\(\\bigcap_{i = 1}^n A_i\\)?\nIf \\(\\{A_n\\}\\) is a decreasing sequence, what is \\(\\bigcap_{n = 1}^\\infty A_n\\)?\nIf \\(\\{A_n\\}\\) is an increasing sequence, what is \\(\\bigcup_{i = 1}^n A_i\\)?\n\n\n\n\n\nThe Cantor set\nThe Cantor set is a subset of the unit interval with the counterintuitive distinction of having uncountably many points, but zero length. It is formed by recursively removing middle thirds, first from the unit interval, and then from each subinterval. This process is illustrated by the picture below.\n\n\n\nRecursively removing middle thirds.\n\n\nEach row represents a set consisting of the union of the shaded intervals, so we are considering a sequence of sets \\(\\{C_n\\}\\) where:\n\\[\n\\begin{align*}\nC_0 &= [0, 1] \\\\\nC_1 &= \\left[0, \\frac{1}{3}\\right] \\cup \\left[\\frac{2}{3}, 1\\right] \\\\\nC_2 &= \\left\\{\\left[0, \\frac{1}{9}\\right] \\cup \\left[\\frac{2}{9}, \\frac{1}{3}\\right]\\right\\} \\cup \\left\\{\\left[\\frac{2}{3}, \\frac{7}{9}\\right] \\cup \\left[\\frac{8}{9}, 1\\right]\\right\\} \\\\\n&\\vdots\n\\end{align*}\n\\] One way to write the recursion explicitly at an arbitrary step \\(n\\) is to consider the left endpoints \\(a_i^{(n - 1)}\\) of the intervals from the previous step in the recursion and express the \\(n\\)th step as:\n\\[\nC_n = \\bigcup_{i = 1}^{2^{n - 1}} \\left\\{ 3^{-n} \\left([0, 1]\\cup[2, 3]\\right) + a_i^{(n - 1)} \\right\\}\n\\]\n(In this expression, \\(c\\times[a, b] + d\\) is shorthand for \\([ca + d, cb + d]\\) and \\(\\times, +\\) distribute over unions.)\nNote that the sequence \\(\\{C_n\\}\\) is monotonic and strictly decreasing. The Cantor set is defined as the limit of this sequence:\n\\[\nC^* = \\lim_{n \\rightarrow \\infty} C_n = \\bigcap_{n = 0}^\\infty C_n\n\\]\nThe total length of any of the sets in the sequence is the sum of the lengths of the component intervals. The component intervals all have the same length \\(3^{-n}\\), so:\n\\[\n\\text{length}(C_n) = \\sum_{i = 1}^{2^n} 3^{-n} = \\left(\\frac{2}{3}\\right)^n\n\\longrightarrow 0 \\quad\n\\text{ as } \\quad n \\rightarrow \\infty\n\\]\nAlthough it requires proof that \\(\\text{length}(\\lim_n C_n) = \\lim_n \\text{length}(C_n)\\), this should seem plausible. (We will prove this result a little later.) Thus, then Cantor set has zero total length:\n\\[\n\\text{length}(C^*) = \\text{length}\\left(\\lim_{n \\rightarrow \\infty} C_n\\right) = \\lim_{n \\rightarrow \\infty}\\text{length}(C_n) = 0\n\\]\nFor this reason, and also from the construction of the Cantor set (as the limit of a sequence of countable unions of geometrically shrinking closed intervals) one would expect that \\(C^*\\) is countable. But in fact one can construct a one-to-one correspondence between the points in \\(C^*\\) and the points in the unit interval \\([0, 1]\\). (The trick is to observe that the ternary (base-3) decimal representation of any point in \\(C^*\\) only utilizes two unique digits and can thus be mapped to a binary decimal representation of a point in the unit interval in a way that is obviously bijective.) This establishes that \\(|C^*| = |[0, 1]|\\) — there are exactly the same number of points in the Cantor set as there are in the unit interval — and therefore that the Cantor set is uncountable!"
  },
  {
    "objectID": "content.html",
    "href": "content.html",
    "title": "Materials",
    "section": "",
    "text": "Week 0 (9/21/23)\nClass meetings:\n\nThursday: course introduction [slides]\n\nAssignments:\n\nComplete intake survey\n\n\n\nWeek 1 (9/25/23)\nSuggested reading:\n\nDG&S 1.4 — 1.6\n\nLecture notes:\n\n[sets]\n[probability measures]\n\nClass meetings:\n\nMonday: sets\nTuesday: sets, cont’d\nWednesday: probability spaces\nThursday: properties of probability measures\n\nAssignment:\n\nHomework 1 due Thursday 10/5\n\n\n\nWeek 2 (10/2/23)\nSuggested reading:\n\nDG&S 1.7 — 1.10\n\nLecture notes:\n\n[counting]\n\nClass meetings:\n\nMonday: wrap-up; probability on finite sample spaces\nTuesday: counting principles and multiplication rules\nWednesday: combinations and permutations\nThursday: combinations and permutations"
  },
  {
    "objectID": "content/week2-counting.html",
    "href": "content/week2-counting.html",
    "title": "Counting rules",
    "section": "",
    "text": "Suppose \\(S = \\{s_1, \\dots, s_n\\}\\) and \\(\\mathcal{S} = 2^S\\). Let \\(\\{p_i\\}\\) be \\(n\\) numbers such that \\(0 \\leq p_i \\leq 1\\) and \\(\\sum_{i = 1}^n p_i = 1\\). Then the set function\n\\[\nP(E) = \\sum_{i: x_i \\in E} p_i \\quad,\\; E\\in \\mathcal{S}\n\\]\nis a probability measure on \\((S, \\mathcal{S})\\), i.e., \\((S, \\mathcal{S}, P)\\) is a probability space.\n\n\n\n\n\n\nProof\n\n\n\nSince by construction \\(\\mathcal{S}\\) is a \\(\\sigma\\)-algebra, it remains only to check that \\(P\\) satisfies the probability axioms.\n\nAxiom 1: \\(P(E) = \\sum_{i: x_i \\in E} p_i \\geq 0\\) since by hypothesis \\(p_i \\geq 0\\).\nAxiom 2: \\(P(S) = \\sum_{i: x_i \\in E} p_i = \\sum_{i = 1}^n p_i = 1\\).\nAxiom 3: let \\(\\{E_j\\}\\) be disjoint and define \\(I_j = \\{i: x_i \\in E_j\\}\\). Note that \\(\\left\\{i: x_i \\in \\bigcup_j E_j\\right\\} = \\bigcup_j I_j\\) and \\(I_j \\cap I_k = \\emptyset\\) for \\(j \\neq k\\). Then: \\[\nP\\left(\\bigcup_j E_j\\right) = \\sum_{\\bigcup_j I_j} p_i = \\sum_j \\sum_{I_j} p_i = \\sum_j P(E_j)\n\\]\n\n\n\nSo, probability measures on finite sample spaces are simply assignments of numbers in \\([0, 1]\\) to each outcome that sum to one.\nNow, if one has equally likely outcomes in a finite sample space, i.e., \\(p_i = p_j\\), then: \\[\nP(E) = \\sum_{i: x_i \\in E} p_i = \\sum_{i: x_i \\in E} \\frac{1}{|S|} = \\frac{|E|}{|S|}\n\\]\nThus, for finite probability spaces with equally likely outcomes, computing event probabilities is a matter of counting. While conceptually straightforward, it is often nontrivial to count the elements in a set. For example, how would you count the number of ways to draw a 3-of-a-kind in a 5-card poker hand? In other words, how many distinct combinations of 5 cards contain exactly three of matching rank and no other matches? For that matter, how many 5-card poker hands are possible? Once you know the answer, finding the probability of a 3-of-a-kind (or obtaining one by drawing 5 cards at random, anyway) is easy; counting the outcomes is the tricky part."
  },
  {
    "objectID": "content/week2-counting.html#footnotes",
    "href": "content/week2-counting.html#footnotes",
    "title": "Counting rules",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe notation \\([x_1, \\dots, x_n]\\) is an ad-hoc expression for the unordered collection consisting of \\(x_1, \\dots, x_n\\) possibly non-distinct elements. Some special notation is needed here because when the collection includes duplicates, it cannot be written as a set. For instance, \\(\\{0, 0, 1\\} = \\{0, 1\\}\\) but \\([0, 0, 1] \\neq [0, 1]\\).↩︎"
  },
  {
    "objectID": "content/week1-probability.html",
    "href": "content/week1-probability.html",
    "title": "Probability measures",
    "section": "",
    "text": "Consider an experiment or random process and define the sample space to be:\n\\[\nS: \\text{ set of all possible outcomes}\n\\]\nAn event is a subset \\(E \\subseteq S\\).1 Its complement is defined as the set \\(E^C = S\\setminus E\\). Note that \\(\\left(E^C\\right)^C = E\\). It is immediate from previous results that, given any events \\(A, B\\):\n\\[\n(A\\cup B)^C = A^C \\cap B^C\n\\qquad\\text{and}\\qquad\n(A\\cap B)^C = A^C \\cup B^C\n\\] Recursive application of this property yields DeMorgan’s laws:\n\\[\n\\left[\\bigcup_{i = 1}^n A_i\\right]^C = \\bigcap A_i^c\n\\qquad\\text{and}\\qquad\n\\left[\\bigcap_{i = 1}^n A_i\\right]^C = \\bigcup A_i^c\n\\]\nThe proof is by induction, and we’ll review it in class. The base case is already established. For the inductive step, one need only reapply the base case replacing \\(A\\) by \\(\\bigcup_{i = 1}^n A_i\\) and \\(B\\) by \\(A_{n + 1}\\).\nTwo events \\(E_1, E_2 \\subseteq S\\) are disjoint just in case they share no outcomes, that is, if \\(E_1 \\cap E_2 = \\emptyset\\).\nA collection of events \\(\\{E_i\\}\\) is mutually disjoint just in case every pair is disjoint, that is, if:\n\\[\nE_i \\cap E_j = \\emptyset\n\\quad\\text{for all}\\quad\ni \\neq j\n\\]\nA partition is a mutually disjoint collection whose union contains an event of interest. Usually, one speaks of a partition of the sample space \\(S\\), i.e., a collection \\(\\{E_i\\}\\) such that:\n\n\\(\\{E_i\\}\\) are mutually disjoint events\n\\(\\bigcup_i E_i = S\\)\n\nNote that \\(\\{E, E^C\\}\\) always form a partition of the sample space for any event \\(E\\).\n\n\n\n\n\n\nCheck your understanding\n\n\n\nLet \\(S = [0, 2], E_1 = (0, 1), E_2 = \\{0, 1, 2\\}, E_3 = (0, 2)\\).\n\nAre \\(E_1\\) and \\(E_2\\) disjoint?\nAre \\(E_2\\) and \\(E_3\\) disjoint?\nDoes the collection \\(\\{E_1, E_2, E_3\\}\\) form a partition of \\(S\\)?\nFind the set \\(E_4\\) such that \\(\\{E_1, E_2, E_4\\}\\) partition \\(S\\)."
  },
  {
    "objectID": "content/week1-probability.html#footnotes",
    "href": "content/week1-probability.html#footnotes",
    "title": "Probability measures",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTechnically, not every subset of \\(S\\) is necessarily an event. This won’t matter especially for this course, but it’s worth mentioning here.↩︎\nIn these notes \\(P\\) is explicitly defined as having range \\([0, 1]\\), so this property may seem redundant. However, most sources simply define \\(P\\) as a real-valued function, in which case this property must be derived. The property is included here to underscore that the \\([0, 1]\\) range is in fact a consequence of the axioms, and not an assumption.↩︎"
  },
  {
    "objectID": "content/week0-intro.html#hi-im-trevor",
    "href": "content/week0-intro.html#hi-im-trevor",
    "title": "Welcome to STAT 425!",
    "section": "Hi I’m Trevor",
    "text": "Hi I’m Trevor\nYou can call me Trevor (if you like).\n\nPronouns: he/him/his\nHometown: Galesville, MD\nFun fact: I like to juggle (clubs, balls)\nOffice: Building 25 Room 236 (25-236)\nEmail: truiz01@calpoly.edu\nWeb: tdruiz.com"
  },
  {
    "objectID": "content/week0-intro.html#warm-up",
    "href": "content/week0-intro.html#warm-up",
    "title": "Welcome to STAT 425!",
    "section": "Warm-up",
    "text": "Warm-up\nIn groups of 3-4:\n\ngo around and say your name, hometown, and current class standing\nwrite down 3 words, concepts, facts, statements, ideas, or phrases you associate with probability (can be one per person or by consensus, your choice)\n\nAfter 5 minutes I’ll go around the room, ask you to share, and transcribe."
  },
  {
    "objectID": "content/week0-intro.html#what-is-probability",
    "href": "content/week0-intro.html#what-is-probability",
    "title": "Welcome to STAT 425!",
    "section": "What is probability?",
    "text": "What is probability?\nBased on our collective facts, can we…\n\nidentify common themes?\nposit a rough definition or description consistent with our ideas?"
  },
  {
    "objectID": "content/week0-intro.html#interpretations-of-probability",
    "href": "content/week0-intro.html#interpretations-of-probability",
    "title": "Welcome to STAT 425!",
    "section": "Interpretations of probability",
    "text": "Interpretations of probability\nThe expression \\(Pr(\\text{Millicent will go for a hike}) = 0.8\\) represents the statement ‘there’s an 80% chance Millicent will go for a hike’. But what does that mean?\n\n(subjective) we are 80% certain that Millicent will go for a hike\n(objective) if we keep presenting Millicent with the same opportunity and circumstances, she’ll go for a hike on 8 out of every 10 occasions"
  },
  {
    "objectID": "content/week0-intro.html#interpretations-of-probability-1",
    "href": "content/week0-intro.html#interpretations-of-probability-1",
    "title": "Welcome to STAT 425!",
    "section": "Interpretations of probability",
    "text": "Interpretations of probability\nThe subjective and objective interpretations of probability have names.\n\nepistemic interpretation: probability statements indicate degrees of belief\naleatory interpretation: probability statements indicate frequencies of occurrence\n\nThe mathematics we’ll study are agnostic on the question of interpretation, though classical examples tend to align more naturally with the aleatory view (games of chance, dice rolls, etc.)."
  },
  {
    "objectID": "content/week0-intro.html#an-informal-definition",
    "href": "content/week0-intro.html#an-informal-definition",
    "title": "Welcome to STAT 425!",
    "section": "An informal definition",
    "text": "An informal definition\nProbability is the mathematics of random events.\nIn this class we’ll develop a formal language for probability in terms of outcomes and events in a sample space:\n\noutcome — result of an experiment or random process\nevent — statement about outcomes\nsample space — collection of all possible outcomes\n\nUsing that language, we’ll construct familiar concepts of random variables, distributions, and their properties.\nSince you already have some exposure/intuition from STAT 305 (or similar), the challenging part of this class for most of you will be the novel formalism and the level of problem-solving expected."
  },
  {
    "objectID": "content/week0-intro.html#stat-425-at-a-glance",
    "href": "content/week0-intro.html#stat-425-at-a-glance",
    "title": "Welcome to STAT 425!",
    "section": "STAT 425 at a glance",
    "text": "STAT 425 at a glance\nScope: we’ll cover probability axioms and properties, random variables, univariate and joint distributions and their properties.\nFormat: we’ll develop a set of course notes in class on the whiteboard following outlines that will be posted in advance of each class meeting; these will cover definitions, properties, theorems, and worked examples.\nMaterials: bring note-taking apparatus (pen/paper, tablet, etc.) and an internet-connected device to each class meeting. There is no required textbook, and the recommended text is available in StatLab (25-107B).\nAssessments: weekly homeworks (7); monthly midterms (2); quarterly final exam (1)."
  },
  {
    "objectID": "content/week0-intro.html#learning-outcomes",
    "href": "content/week0-intro.html#learning-outcomes",
    "title": "Welcome to STAT 425!",
    "section": "Learning outcomes",
    "text": "Learning outcomes\n(…with emphasis on key phrases)\n\nuse the axiomatic construction of probability to derive properties of probability measures and conditional probability measures, and apply definitions and properties to solve probability problems \nconstruct probability models for discrete and continuous random variables, develop familiarity with common probability distributions, and use distribution functions to derive properties such as expectations and variances \ndetermine joint distributions for collections of random variables, and use joint distribution functions to (a) derive properties such as covariance and correlation, (b) to determine conditional and marginal distributions, and (c) derive distributions of transformations and functions of one or more random variables \n\nNote the frequent occurrence of the word use! I want you to understand and be able to use the concepts we discuss in class."
  },
  {
    "objectID": "content/week0-intro.html#assessment-and-evaluation",
    "href": "content/week0-intro.html#assessment-and-evaluation",
    "title": "Welcome to STAT 425!",
    "section": "Assessment and evaluation",
    "text": "Assessment and evaluation\n\nHomeworks (50%). Assigned/collected Thursdays; collaboration allowed; evaluated based on completeness, organization, and correctness of selected answers; lowest score dropped from final grade calculation.\nMidterms (30%). Given in class Thursdays of weeks 4 and 8; note sheet allowed; evaluated based on completeness and correctness; higher score weighted more heavily in final grade calculation.\nFinal exam (20%). Administered as scheduled by Registrar; note sheet allowed; cumulative but emphasizes later material; evaluated based on completeness and correctness.\n\nWe aim to return graded work within one week, except for the final exam, which I’ll keep.\nLetter grades (to within \\(\\pm 5\\)): A: 90-100. B: 75-90. C: 60-75. D: 50-60."
  },
  {
    "objectID": "content/week0-intro.html#select-policies",
    "href": "content/week0-intro.html#select-policies",
    "title": "Welcome to STAT 425!",
    "section": "Select policies",
    "text": "Select policies\n\nTime. Expect about 12-16 hours per week, including class time. Let me know if you’re exceeding this amount so I can help.\nCollaboration. Allowed within the class only. Collaborations must reflect a legitimate shared effort, and names of collaborators should be written on submissions.\nAttendance. Everyone is allowed two ‘free’ absences without notice at any time for any reason. Subsequent absences must be excusable and you should notify me by email.\nDeadlines. Everyone is allowed two ‘free’ late homework submissions without notice at any time for any reason. Subsequent late submissions will be evaluated for 75% credit."
  },
  {
    "objectID": "content/week0-intro.html#select-policies-1",
    "href": "content/week0-intro.html#select-policies-1",
    "title": "Welcome to STAT 425!",
    "section": "Select policies",
    "text": "Select policies\n\nGrades. Please report any discrepancies/errors in evaluation promptly (within 1 week of receiving an evaluated submission). Attempting to negotiate grades or seeking reevaluations after final grades are posted is not appropriate.\nCommunication. I prefer office hours and before/in/after class discussion for most matters. I try to respond to email within 48 weekday hours. Please wait a week before sending reminders, unless it’s time sensitive.\nConduct. Instances of academic dishonesty will be reported to OSRR and consequences may range from loss of credit to automatic failure, depending on the severity of the act."
  },
  {
    "objectID": "content/week0-intro.html#general-advice",
    "href": "content/week0-intro.html#general-advice",
    "title": "Welcome to STAT 425!",
    "section": "General advice",
    "text": "General advice\nI want each of you to succeed in this course and am here to help. I have a few recommendations:\n\nspend 15-30 minutes skimming the suggested textbook sections each week in the StatLab\ntake advantage of the collaboration policy and work with classmates on homework\nuse your free absences and late submissions wisely\ncome to me early with any obstacles or difficulties you’re facing\ntake advantage of office hours; it’s time each week that I set aside specifically for you"
  },
  {
    "objectID": "content/week0-intro.html#for-next-time",
    "href": "content/week0-intro.html#for-next-time",
    "title": "Welcome to STAT 425!",
    "section": "For next time",
    "text": "For next time\n\nComplete intake survey\nCheck the website before class for a lecture outline\n\n\n\n\n© 2023 Trevor Ruiz"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Announcements\n\n\n\n\nHW1 due 10/5 in class; problem 5 is optional\nWeek 2 notes posted\nThis week only, Thursday 1-3 office hour changed to W 2-3 and Th 1-2.\n\n\n\nThis is the class website for Probability Theory (STAT 425) offered at Cal Poly in Fall 2023. Note that this site is for both sections (01-3585 held 4:10pm MTWR and 02-3430 held 5:10pm MTWR).\nMaterial posted on this site is intended for use by currently enrolled students for course-related purposes only. Please do not reproduce any material on this site without permission."
  }
]